{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mfr3ak/PyTorch-Practice/blob/PyTorch_Practice_Solutions/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "9ad3b2fc-99b1-4360-b3d1-84f8e415859e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 24 16:41:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "158846af-9c5f-4db9-f82f-8ee6a5dffb9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VyWRkvWGbCXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1rxD6GObCqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ocvOdWKcbEKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets.mnist import MNIST\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = MNIST(root=\"data\",\n",
        "                   download=True,\n",
        "                   train = True,\n",
        "                   transform=ToTensor(),\n",
        "                   target_transform= None)\n",
        "\n",
        "test_data = MNIST (root = \"data\",\n",
        "                   download = True,\n",
        "                   train = False,\n",
        "                   transform = ToTensor(),\n",
        "                   target_transform = None)"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "outputId": "0d6ee47c-8ed4-46d7-c5a9-b88f1ef62bfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 150781406.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 48629343.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 51773017.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20484439.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = torch.randint(0,len(train_data),(1,)).squeeze()\n",
        "print(idx)\n",
        "img,label = train_data[idx]\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img.squeeze())"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "outputId": "53f08f9f-b570-46d4-d0f9-17c04743e461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5154)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x789bacf6d7e0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset = train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset = test_data,\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             shuffle = True)"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class MNISTCNNV0(nn.Module):\n",
        "    def __init__(self, input_states, hidden_states, output_states):\n",
        "        super().__init__()\n",
        "        self.Conv_Layer_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_states,\n",
        "                      out_channels=hidden_states,\n",
        "                      kernel_size = 3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = hidden_states,\n",
        "                      out_channels = hidden_states,\n",
        "                      kernel_size = 3,\n",
        "                      padding = 1,\n",
        "                      stride = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         padding = 0))\n",
        "        self.Conv_Layer_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_states,\n",
        "                      out_channels=hidden_states,\n",
        "                      kernel_size = 3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = hidden_states,\n",
        "                      out_channels = hidden_states,\n",
        "                      kernel_size = 3,\n",
        "                      padding = 1,\n",
        "                      stride = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         padding = 0)\n",
        "        )\n",
        "        self.Linear_layer = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features = (hidden_states*7*7),\n",
        "                      out_features = output_states)\n",
        "        )\n",
        "\n",
        "    def forward(self,X):\n",
        "        x = self.Conv_Layer_1(X)\n",
        "        print(x.shape)\n",
        "        x = self.Conv_Layer_2(x)\n",
        "        print(x.shape)\n",
        "        x = self.Linear_layer(x)\n",
        "        print(x.shape)\n",
        "        return x\n",
        "\n",
        "model_2 = MNISTCNNV0(1,10,10)\n",
        "print(model_2)"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS",
        "outputId": "d7a4754d-061a-4f46-eaef-4dd7f99bbab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNISTCNNV0(\n",
            "  (Conv_Layer_1): Sequential(\n",
            "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (Conv_Layer_2): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (Linear_layer): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_2)"
      ],
      "metadata": {
        "id": "DFfzE8Kmyt_i",
        "outputId": "e4c8a80d-709e-4138-ca8a-576c2c7de73a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNISTCNNV0(\n",
            "  (Conv_Layer_1): Sequential(\n",
            "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (Conv_Layer_2): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (Linear_layer): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "tvTz6EvHzLLu",
        "outputId": "2af049e1-d2eb-4588-b221-087de0dcfaaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2(img)"
      ],
      "metadata": {
        "id": "dNG4j5HBxXuC",
        "outputId": "6b3bb398-832f-42b4-93ae-422ab53625be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 14, 14])\n",
            "torch.Size([10, 7, 7])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-1e5676fed733>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-4a25f02c1b4d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv_Layer_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x49 and 490x10)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp,labels = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "V6SZb_fgw8e0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = temp[0]"
      ],
      "metadata": {
        "id": "6T882L6IxGGY"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_2.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "cxKJ-2wPvGX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "torch.manual_seed(42)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    print(f\"Epoch : {epoch}--------------\")\n",
        "    train_loss = 0\n",
        "    for batch_number, (X, y) in enumerate(train_dataloader):\n",
        "        print(f\"Current Batch Number : {batch_number}\")\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # training pass\n",
        "        y_logits = model_2(X)\n",
        "        y_probs = torch.softmax(y_logits, dim = 0)\n",
        "        y_preds = torch.argmax(y_probs, dim = 1)\n",
        "\n",
        "        train_loss_temp = loss_fn(y_logits,y)\n",
        "        optimizer.zero_grad()\n",
        "        train_loss_temp.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += train_loss_temp\n",
        "    print(f\"Train_loss:{train_loss/len(train_dataloader)}\")"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}