{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b443d9d6f9340de9a44a9b4cc99e532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cad241e1536b473593301df1fd987e7a",
              "IPY_MODEL_c6fb78b477554d3592fb311e995417fe",
              "IPY_MODEL_8e1d981158b441909330a222766cc15b"
            ],
            "layout": "IPY_MODEL_42b853792e074991913a9282966aab32"
          }
        },
        "cad241e1536b473593301df1fd987e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b76e7919b7874190b8d7774143cfd8da",
            "placeholder": "​",
            "style": "IPY_MODEL_43173073ec674ccc80d8d6fbc3228b7f",
            "value": "100%"
          }
        },
        "c6fb78b477554d3592fb311e995417fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c0c63d07c6475ba1aeb6daff37034b",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f77830a5c4e48c49362b59e44d19185",
            "value": 5
          }
        },
        "8e1d981158b441909330a222766cc15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32e2713857f74a63809854e7096d3d10",
            "placeholder": "​",
            "style": "IPY_MODEL_2f69bdd1430f44e89323898eceef6583",
            "value": " 5/5 [01:07&lt;00:00, 13.96s/it]"
          }
        },
        "42b853792e074991913a9282966aab32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76e7919b7874190b8d7774143cfd8da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43173073ec674ccc80d8d6fbc3228b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49c0c63d07c6475ba1aeb6daff37034b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f77830a5c4e48c49362b59e44d19185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32e2713857f74a63809854e7096d3d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f69bdd1430f44e89323898eceef6583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mfr3ak/PyTorch-Practice/blob/PyTorch_Practice_Solutions/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "a9554508-a854-4665-e158-74ebf6491a78"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 25 19:19:10 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "516b94f0-60e3-4d3d-cc6c-60fdb246ac64"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VyWRkvWGbCXj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1rxD6GObCqh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ocvOdWKcbEKr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets.mnist import MNIST\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = MNIST(root=\"data\",\n",
        "                   download=True,\n",
        "                   train = True,\n",
        "                   transform=ToTensor(),\n",
        "                   target_transform= None)\n",
        "\n",
        "test_data = MNIST (root = \"data\",\n",
        "                   download = True,\n",
        "                   train = False,\n",
        "                   transform = ToTensor(),\n",
        "                   target_transform = None)"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "outputId": "2c30d024-b4be-4124-f257-bd23f446a4d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 111481563.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 26919043.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 20952611.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20572925.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = torch.randint(0,len(train_data),(1,)).squeeze()\n",
        "print(idx)\n",
        "img,label = train_data[idx]\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img.squeeze())"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "outputId": "98d6564d-62de-4e09-a3bd-ff7c5b927114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27019)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a2815530fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset = train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset = test_data,\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             shuffle = False)"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class MNISTCNNV0(nn.Module):\n",
        "    def __init__(self, input_states, hidden_states, output_states):\n",
        "        super().__init__()\n",
        "        self.Conv_Layer_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_states,\n",
        "                      out_channels=hidden_states,\n",
        "                      kernel_size = 3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = hidden_states,\n",
        "                      out_channels = hidden_states,\n",
        "                      kernel_size = 3,\n",
        "                      padding = 1,\n",
        "                      stride = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         padding = 0))\n",
        "        self.Conv_Layer_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_states,\n",
        "                      out_channels=hidden_states,\n",
        "                      kernel_size = 3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels = hidden_states,\n",
        "                      out_channels = hidden_states,\n",
        "                      kernel_size = 3,\n",
        "                      padding = 1,\n",
        "                      stride = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         padding = 0)\n",
        "        )\n",
        "        self.Linear_layer = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features = hidden_states*7*7,\n",
        "                      out_features = output_states)\n",
        "        )\n",
        "\n",
        "    def forward(self,X):\n",
        "        x = self.Conv_Layer_1(X)\n",
        "        x = self.Conv_Layer_2(x)\n",
        "        x = self.Linear_layer(x)\n",
        "        return x\n",
        "\n",
        "model_2 = MNISTCNNV0(1,10,10).to(device)\n",
        "print(model_2)"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS",
        "outputId": "7148206c-8897-48bc-ff31-ac9fd843f62e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNISTCNNV0(\n",
            "  (Conv_Layer_1): Sequential(\n",
            "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (Conv_Layer_2): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (Linear_layer): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_2)"
      ],
      "metadata": {
        "id": "DFfzE8Kmyt_i",
        "outputId": "682f9d9b-af51-4c05-a6ba-997b6b47062a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNISTCNNV0(\n",
            "  (Conv_Layer_1): Sequential(\n",
            "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (Conv_Layer_2): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (Linear_layer): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp,labels = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "V6SZb_fgw8e0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = temp[0].unsqueeze(dim=0).to(device)"
      ],
      "metadata": {
        "id": "6T882L6IxGGY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2(img)"
      ],
      "metadata": {
        "id": "0yYKEGSD-P8b",
        "outputId": "d038a8df-8c9d-43e7-dbd0-3571e7f1d222",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0438, -0.0591,  0.0086, -0.1332,  0.0145, -0.0675, -0.0227,  0.0023,\n",
              "          0.0250,  0.0040]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_2.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "cxKJ-2wPvGX7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "torch.manual_seed(42)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    print(f\"Epoch : {epoch}--------------\")\n",
        "    train_loss = 0\n",
        "    for batch_number, (X, y) in enumerate(train_dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # training pass\n",
        "        y_logits = model_2(X)\n",
        "        y_probs = torch.softmax(y_logits, dim = 0)\n",
        "        y_preds = torch.argmax(y_probs, dim = 1)\n",
        "\n",
        "        train_loss_temp = loss_fn(y_logits,y)\n",
        "        optimizer.zero_grad()\n",
        "        train_loss_temp.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += train_loss_temp\n",
        "    print(f\"Train_loss:{train_loss/len(train_dataloader)}\")\n",
        "\n",
        "    # Testing step\n",
        "    test_loss = 0\n",
        "    model_2.eval()\n",
        "    with torch.inference_mode():\n",
        "        for batch_number, (X_test,y_test) in enumerate(test_dataloader):\n",
        "            X_test = X_test.to(device)\n",
        "            y_test = y_test.to(device)\n",
        "            y_logits_test = model_2(X_test)\n",
        "            y_prob_test = torch.softmax(y_logits_test, dim = 0)\n",
        "            y_preds_test= torch.argmax(y_prob_test, dim = 1)\n",
        "\n",
        "            test_loss += loss_fn(y_logits_test, y_test)\n",
        "        print(f\"Test_loss:{test_loss/len(test_dataloader)}\")"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD",
        "outputId": "8d496c88-507f-4f76-84b8-aa3d80bc2c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "0b443d9d6f9340de9a44a9b4cc99e532",
            "cad241e1536b473593301df1fd987e7a",
            "c6fb78b477554d3592fb311e995417fe",
            "8e1d981158b441909330a222766cc15b",
            "42b853792e074991913a9282966aab32",
            "b76e7919b7874190b8d7774143cfd8da",
            "43173073ec674ccc80d8d6fbc3228b7f",
            "49c0c63d07c6475ba1aeb6daff37034b",
            "0f77830a5c4e48c49362b59e44d19185",
            "32e2713857f74a63809854e7096d3d10",
            "2f69bdd1430f44e89323898eceef6583"
          ]
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b443d9d6f9340de9a44a9b4cc99e532"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0--------------\n",
            "Train_loss:1.1228055953979492\n",
            "Test_loss:0.2187422662973404\n",
            "Epoch : 1--------------\n",
            "Train_loss:0.17085714638233185\n",
            "Test_loss:0.10378216207027435\n",
            "Epoch : 2--------------\n",
            "Train_loss:0.10761585086584091\n",
            "Test_loss:0.0815470814704895\n",
            "Epoch : 3--------------\n",
            "Train_loss:0.08773671090602875\n",
            "Test_loss:0.07813568413257599\n",
            "Epoch : 4--------------\n",
            "Train_loss:0.0753052607178688\n",
            "Test_loss:0.057839132845401764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}